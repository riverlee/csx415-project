---
title: "Tree Model Performance"
subtitle: "Predict gestational diabetes"
author: "Jiang Li"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    keep_md: yes
    toc_float:
      collapsed: false
      smooth_scroll: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning  = FALSE)
knitr::opts_knit$set(root.dir = "../../GDM/" )
```

## Load Data

We will use [ProjectTemplate](http://projecttemplate.net/) to layout my project. When load the project, we will split the **diabetes** dataset into train and test dataset, namely **trainDat** (70%) and **testDat**(remaining 30%).


```{r load,cache=FALSE}
library(ProjectTemplate)
load.project()
ls()
```

The mung code to read the csv files and split it into trainning (**trainDat**) and testing(**testDat**) dataset is located in **GDM/munge/01-A.R**. Code is listed below

```{r code,eval=FALSE,}
# Example preprocessing script.

## split the diabetes dataset into train and test ##
set.seed(1)
diabetes$Outcome = as.factor(diabetes$Outcome)
inTrain <- createDataPartition(diabetes$Outcome, p = 0.70 , list = FALSE)
trainDat <- diabetes[ inTrain, ]
testDat <- diabetes[ -inTrain, ]
rm(inTrain
```


## Explanatory analysis

### What are the features

There are 8 features in the dataset
```{r features}
library(tidyverse)
glimpse(diabetes)

```

### Number of positive and negative samples

**268** samples have diabetes(positive) while **500** samples don't have diabetes (negatove)

```{r}
diabetes %>%
  count(Outcome) %>%
  mutate(type = ifelse(Outcome==1,"Diabetes","Non-Diabetes")) %>%
  ggplot(aes(type,n,fill=type)) + 
    geom_bar(stat="identity")+
    geom_text(aes(label=n))+
    xlab("")+ylab("Number")+
    ggtitle("Number of samples")
```


### Look at each feature's distribution between positives and negatives

**Will first normalize each feature's value into [0,1] ranges**

```{r dist}
## Scale to 0,1
scale.0.1 <-function(x){
  (x-min(x))/(max(x)-min(x))
}

diabetes %>%
  mutate_each(funs(scale.0.1),-Outcome) %>%
  gather(key=feature,value = value,-Outcome) %>%
  ggplot(aes(value,color=Outcome))+
    geom_density()+
    facet_wrap(~feature,ncol=4)
```





## Tree Model performance

### Use all features

- The AUC on training and testing is 0.884 and 0.750 separately.
- It looks the data is over fitting on the trainning set

```{r treeM}
## Will train model on the trainDat
library(rpart)
model.rpart = rpart(Outcome~.,data = trainDat,method = "class", control = rpart.control(cp = 0))

library(rpart.plot)
rpart.plot(model.rpart)
#summary(model.rpart)

## Look performance on the trainning and test dataset
pf.test <- testDat %>%
  select(Outcome) %>%
  mutate(predicted.prob = predict(model.rpart,testDat,type="prob")[,2],
         predicted = predict(model.rpart,testDat,type="class"),
         dataset = "Test")

pf.train <- trainDat %>%
  select(Outcome) %>%
  mutate(predicted.prob = predict(model.rpart,trainDat,type="prob")[,2],
          predicted = predict(model.rpart,trainDat,type="class"),
         dataset = "Train")

### 
library(pROC)
ROC.train <- roc(pf.train$Outcome,pf.train$predicted.prob )
ROC.test <- roc(pf.test$Outcome,pf.test$predicted.prob )

# Plot the ROC curve
sp.se = data_frame(specificity = c(ROC.train$specificities,ROC.test$specificities),
                   sensitivity = c(ROC.train$sensitivities,ROC.test$sensitivities),
                   type = c(rep("Trainning",length(ROC.train$specificities)),
                            rep("Testing",length(ROC.test$specificities)))
)

cat("rpart Model performance (AUC)")
(model.auc = data_frame(AUC = c(auc(ROC.train),auc(ROC.test)),
                       type=c("Trainning","Testing")))

model.auc.text <- model.auc %>%
        transmute(auc=paste(type,round(AUC,4),sep=":")) %>%
        as.data.frame()

model.auc.text = paste( model.auc.text[,1],collapse = "\n")
                

save(model.auc,file ="result/model.auc.rpart.Rda")
ggplot(sp.se,aes(x = 1-specificity,y=sensitivity,color=type))+
    geom_line() +
    geom_abline(slope = 1,color='grey')+
    ggtitle("ROC of rpart model") +
    geom_text(aes(x=.75,y=.5,label=model.auc.text))

```


### Use a subset of features

- Use only features of **Pregnancies**, **Glucose**, **BloodPressure** ,**DiabetesPedigreeFunction** and **BMI**
- The AUC on training and testing is 0.892 and 0.764 separately - **Using 5 features Increase the performance**
- It looks over fitting on the trainning dataset

```{r treeM2}
## Will train model on the trainDat
model.rpart2 = trainDat %>%
  select(Pregnancies,Glucose,BloodPressure,BMI,DiabetesPedigreeFunction,Outcome) %>%
  rpart(Outcome~.,data = .,method = "class", control = rpart.control(cp = 0))

rpart.plot(model.rpart2)
#summary(model.rpart2)

## Look performance on the trainning and test dataset

pf.test2 <- testDat %>%
  select(Outcome) %>%
  mutate(predicted.prob = predict(model.rpart2,testDat,type="prob")[,2],
         predicted = predict(model.rpart2,testDat,type="class"),
         dataset = "Test")

pf.train2 <- trainDat %>%
  select(Outcome) %>%
  mutate(predicted.prob = predict(model.rpart2,trainDat,type="prob")[,2],
          predicted = predict(model.rpart2,trainDat,type="class"),
         dataset = "Train")

### 
ROC.train2 <- roc(pf.train2$Outcome,pf.train2$predicted.prob )
ROC.test2 <- roc(pf.test2$Outcome,pf.test2$predicted.prob )

# Plot the ROC curve
sp.se = data_frame(specificity = c(ROC.train2$specificities,ROC.test2$specificities),
                   sensitivity = c(ROC.train2$sensitivities,ROC.test2$sensitivities),
                   type = c(rep("Trainning",length(ROC.train2$specificities)),
                            rep("Testing",length(ROC.test2$specificities)))
)

cat("rpart Model performance (AUC)")
(model.auc = data_frame(AUC = c(auc(ROC.train2),auc(ROC.test2)),
                       type=c("Trainning","Testing")))


ggplot(sp.se,aes(x = 1-specificity,y=sensitivity,color=type))+
    geom_line() +
    geom_abline(slope = 1,color='grey')+
    ggtitle("ROC of rpart model") +
    geom_text(aes(x=.75,y=.5,label=model.auc.text))

```


















